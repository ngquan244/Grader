"""
Quiz Generator Module
=====================
Generate quiz questions from documents using RAG + Ollama LLM.
"""

import logging
import json
import re
from typing import List, Dict, Any, Optional

from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama import ChatOllama
from pydantic import BaseModel, Field

from .config import rag_config
from .retriever import DocumentRetriever

logger = logging.getLogger(__name__)


# ===== Quiz Data Models =====

class QuizQuestion(BaseModel):
    """Model for a single quiz question"""
    question: str = Field(description="N·ªôi dung c√¢u h·ªèi")
    options: List[str] = Field(description="Danh s√°ch 4 ƒë√°p √°n A, B, C, D")
    correct_answer: str = Field(description="ƒê√°p √°n ƒë√∫ng (A, B, C ho·∫∑c D)")
    explanation: str = Field(description="Gi·∫£i th√≠ch ng·∫Øn g·ªçn t·∫°i sao ƒë√°p √°n ƒë√∫ng")


class QuizOutput(BaseModel):
    """Model for quiz generation output"""
    quiz: List[QuizQuestion] = Field(default=[], description="Danh s√°ch c√¢u h·ªèi")
    message: str = Field(default="", description="Th√¥ng b√°o n·∫øu c√≥ l·ªói")


# ===== Prompt Template =====

QUIZ_GENERATION_PROMPT = """B·∫°n l√† m·ªôt gi√°o vi√™n chuy√™n nghi·ªáp trong vi·ªác so·∫°n ƒë·ªÅ thi tr·∫Øc nghi·ªám ch·∫•t l∆∞·ª£ng cao.

NHI·ªÜM V·ª§: T·∫°o {num_questions} c√¢u h·ªèi tr·∫Øc nghi·ªám d·ª±a tr√™n n·ªôi dung t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p.

N·ªòI DUNG T√ÄI LI·ªÜU (CONTEXT):
{context}

CH·ª¶ ƒê·ªÄ/Y√äU C·∫¶U: {topic}

ƒê·ªò KH√ì: {difficulty} (easy/medium/hard)

QUY T·∫ÆC B·∫ÆT BU·ªòC:
1. CH·ªà s·ª≠ d·ª•ng th√¥ng tin c√≥ trong Context ƒë·ªÉ t·∫°o c√¢u h·ªèi
2. KH√îNG b·ªãa ƒë·∫∑t ho·∫∑c th√™m ki·∫øn th·ª©c ngo√†i t√†i li·ªáu
3. M·ªói c√¢u h·ªèi PH·∫¢I c√≥ ƒë√∫ng 4 ƒë√°p √°n: A, B, C, D
4. C√°c ƒë√°p √°n sai ph·∫£i h·ª£p l√Ω, kh√¥ng qu√° d·ªÖ lo·∫°i tr·ª´
5. C√¢u h·ªèi ph·∫£i r√µ r√†ng, kh√¥ng m∆° h·ªì
6. Tu√¢n th·ªß ƒë·ªô kh√≥ y√™u c·∫ßu:
   - easy: C√¢u h·ªèi ƒë∆°n gi·∫£n, ki·ªÉm tra ghi nh·ªõ c∆° b·∫£n
   - medium: C√¢u h·ªèi y√™u c·∫ßu hi·ªÉu v√† √°p d·ª•ng ki·∫øn th·ª©c
   - hard: C√¢u h·ªèi ph√¢n t√≠ch, so s√°nh, t·ªïng h·ª£p th√¥ng tin
7. Tr√°nh c√¢u h·ªèi tr√πng l·∫∑p √Ω nghƒ©a

H∆Ø·ªöNG D·∫™N T·∫†O C√ÇU H·ªéI CH·∫§T L∆Ø·ª¢NG:
- C√¢u h·ªèi ki·ªÉm tra hi·ªÉu bi·∫øt, kh√¥ng ch·ªâ ghi nh·ªõ
- ƒê√°p √°n ƒë√∫ng ph·∫£i ch√≠nh x√°c theo t√†i li·ªáu
- Gi·∫£i th√≠ch ng·∫Øn g·ªçn, tr√≠ch d·∫´n t·ª´ context n·∫øu c√≥ th·ªÉ
- N·∫øu context kh√¥ng ƒë·ªß ƒë·ªÉ t·∫°o {num_questions} c√¢u, t·∫°o t·ªëi ƒëa s·ªë c√¢u c√≥ th·ªÉ

X·ª¨ L√ù TR∆Ø·ªúNG H·ª¢P ƒê·∫∂C BI·ªÜT:
- N·∫øu Context KH√îNG ch·ª©a th√¥ng tin v·ªÅ "{topic}": tr·∫£ v·ªÅ quiz r·ªóng v·ªõi message gi·∫£i th√≠ch
- N·∫øu Context kh√¥ng ƒë·ªß th√¥ng tin: t·∫°o √≠t c√¢u h∆°n, KH√îNG b·ªãa

ƒê·ªäNH D·∫†NG OUTPUT (JSON):
{{
  "quiz": [
    {{
      "question": "N·ªôi dung c√¢u h·ªèi?",
      "options": ["ƒê√°p √°n A", "ƒê√°p √°n B", "ƒê√°p √°n C", "ƒê√°p √°n D"],
      "correct_answer": "A",
      "explanation": "Gi·∫£i th√≠ch ng·∫Øn g·ªçn"
    }}
  ],
  "message": ""
}}

CH√ö √ù: Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng th√™m text kh√°c. ƒê·∫£m b·∫£o JSON h·ª£p l·ªá."""


QUIZ_GENERATION_PROMPT_V2 = """You are an expert quiz creator. Create {num_questions} multiple-choice questions based ONLY on the provided document content.

DOCUMENT CONTENT:
{context}

TOPIC/REQUIREMENT: {topic}

DIFFICULTY LEVEL: {difficulty} (easy/medium/hard)

STRICT RULES:
1. Questions MUST be based ONLY on the provided content - DO NOT make up information
2. Each question has exactly 4 options: A, B, C, D
3. Wrong answers should be plausible but clearly incorrect based on the document
4. Follow the difficulty level:
   - easy: Simple recall questions testing basic facts
   - medium: Questions requiring understanding and application
   - hard: Complex questions requiring analysis and synthesis
5. Questions should test understanding, not just memorization
6. If content is insufficient, create fewer questions rather than inventing facts

OUTPUT FORMAT (JSON only, no markdown):
{{
  "quiz": [
    {{
      "question": "Question text here?",
      "options": ["Option A text", "Option B text", "Option C text", "Option D text"],
      "correct_answer": "A",
      "explanation": "Brief explanation why this is correct"
    }}
  ],
  "message": ""
}}

If the topic is not found in the document, return:
{{"quiz": [], "message": "Kh√¥ng t√¨m th·∫•y n·ªôi dung v·ªÅ '{topic}' trong t√†i li·ªáu"}}

Return ONLY valid JSON, no additional text."""


class QuizGenerator:
    """
    Generate quiz questions from documents using RAG.
    """
    
    def __init__(
        self,
        retriever: DocumentRetriever,
        model: Optional[str] = None,
        temperature: Optional[float] = None,
        base_url: Optional[str] = None
    ):
        """
        Initialize Quiz Generator.
        
        Args:
            retriever: DocumentRetriever instance
            model: Ollama model name
            temperature: Generation temperature (lower = more focused)
            base_url: Ollama API base URL
        """
        self.retriever = retriever
        self.model = model or rag_config.OLLAMA_MODEL
        self.temperature = temperature if temperature is not None else 0.3
        self.base_url = base_url or rag_config.OLLAMA_BASE_URL
        
        # Initialize LLM with lower temperature for more consistent output
        self.llm = ChatOllama(
            model=self.model,
            temperature=self.temperature,
            base_url=self.base_url,
            num_ctx=rag_config.OLLAMA_NUM_CTX,
            format="json",  # Request JSON output
        )
        
        # Prompt templates
        self.prompt_vi = ChatPromptTemplate.from_template(QUIZ_GENERATION_PROMPT)
        self.prompt_en = ChatPromptTemplate.from_template(QUIZ_GENERATION_PROMPT_V2)
        
        logger.info(f"QuizGenerator initialized with model: {self.model}")
    
    def generate_quiz(
        self,
        topic: str,
        num_questions: int = 5,
        difficulty: str = "medium",
        language: str = "vi",
        k: int = 10
    ) -> Dict[str, Any]:
        """
        Generate quiz questions based on a topic.
        
        Args:
            topic: Topic or description of what to quiz about
            num_questions: Number of questions to generate
            difficulty: Difficulty level - "easy", "medium", or "hard"
            language: "vi" for Vietnamese prompt, "en" for English
            k: Number of documents to retrieve for context
            
        Returns:
            Dictionary with quiz questions and metadata
        """
        logger.info(f"Generating quiz: topic='{topic}', num_questions={num_questions}, difficulty={difficulty}")
        
        # Step 1: Retrieve relevant documents
        documents = self.retriever.retrieve(topic, k=k)
        
        if not documents:
            logger.warning("No documents retrieved for topic")
            return {
                "success": False,
                "questions": [],
                "message": f"Kh√¥ng t√¨m th·∫•y n·ªôi dung v·ªÅ '{topic}' trong t√†i li·ªáu",
                "sources": []
            }
        
        # Step 2: Format context
        context = self.retriever.format_context(documents)
        
        if not context.strip():
            return {
                "success": False,
                "questions": [],
                "message": "Context r·ªóng, kh√¥ng th·ªÉ t·∫°o quiz",
                "sources": []
            }
        
        # Step 3: Select prompt based on language
        prompt = self.prompt_vi if language == "vi" else self.prompt_en
        
        # Step 4: Generate quiz
        chain = prompt | self.llm
        
        try:
            logger.info("Generating quiz with LLM...")
            
            response = chain.invoke({
                "context": context,
                "topic": topic,
                "num_questions": num_questions,
                "difficulty": difficulty
            })
            
            # Parse response
            content = response.content if hasattr(response, 'content') else str(response)
            logger.info(f"Raw LLM response: {content[:500]}...")
            
            # Parse JSON
            quiz_data = self._parse_quiz_response(content)
            
            if not quiz_data:
                logger.error(f"Failed to parse quiz data from response")
                return {
                    "success": False,
                    "questions": [],
                    "message": "Kh√¥ng th·ªÉ parse k·∫øt qu·∫£ t·ª´ LLM",
                    "sources": self.retriever.extract_citations(documents),
                    "raw_response": content
                }
            
            logger.info(f"Parsed quiz_data keys: {quiz_data.keys()}")
            logger.info(f"Number of quiz items: {len(quiz_data.get('quiz', []))}")
            
            # Check for error message from LLM
            if quiz_data.get("message") and not quiz_data.get("quiz"):
                return {
                    "success": False,
                    "questions": [],
                    "message": quiz_data["message"],
                    "sources": self.retriever.extract_citations(documents)
                }
            
            # Format quiz questions
            formatted_quiz = self._format_quiz(quiz_data.get("quiz", []))
            
            logger.info(f"Generated {len(formatted_quiz)} questions")
            
            if len(formatted_quiz) > 0:
                logger.info(f"Sample question 1: {formatted_quiz[0]}")
            
            return {
                "success": True,
                "questions": formatted_quiz,
                "message": quiz_data.get("message", ""),
                "sources": self.retriever.extract_citations(documents),
                "num_questions_requested": num_questions,
                "num_questions_generated": len(formatted_quiz)
            }
            
        except Exception as e:
            logger.error(f"Error generating quiz: {e}")
            return {
                "success": False,
                "questions": [],
                "message": f"L·ªói khi t·∫°o quiz: {str(e)}",
                "sources": self.retriever.extract_citations(documents),
                "error": str(e)
            }
    
    def _parse_quiz_response(self, content: str) -> Optional[Dict]:
        """Parse JSON response from LLM."""
        try:
            # Try direct JSON parse
            return json.loads(content)
        except json.JSONDecodeError:
            pass
        
        # Try to extract JSON from markdown code block
        json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', content)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                pass
        
        # Try to find JSON object in content
        json_match = re.search(r'\{[\s\S]*\}', content)
        if json_match:
            try:
                return json.loads(json_match.group(0))
            except json.JSONDecodeError:
                pass
        
        logger.error(f"Could not parse JSON from response: {content[:200]}")
        return None
    
    def _format_quiz(self, quiz_list: List[Dict]) -> List[Dict]:
        """Format and validate quiz questions."""
        formatted = []
        
        for i, q in enumerate(quiz_list):
            try:
                # Validate required fields
                if not q.get("question"):
                    logger.warning(f"Question {i} missing 'question' field")
                    continue
                
                if not q.get("options"):
                    logger.warning(f"Question {i} missing 'options' field")
                    continue
                
                options = q.get("options", [])
                
                # Handle if options is already a dict
                if isinstance(options, dict):
                    # Already in {A: ..., B: ..., C: ..., D: ...} format
                    options_dict = options
                else:
                    # Convert list to dict
                    if not isinstance(options, list):
                        logger.warning(f"Question {i}: options is not list or dict: {type(options)}")
                        continue
                    
                    if len(options) != 4:
                        logger.warning(f"Question {i}: options has {len(options)} items, expected 4")
                        # Pad or trim to 4 options
                        while len(options) < 4:
                            options.append(f"ƒê√°p √°n {chr(65 + len(options))}")
                        options = options[:4]
                    
                    options_dict = {
                        "A": options[0],
                        "B": options[1],
                        "C": options[2],
                        "D": options[3]
                    }
                
                # Get correct answer
                correct = q.get("correct_answer", "A").upper()
                if correct not in ["A", "B", "C", "D"]:
                    logger.warning(f"Question {i}: invalid correct_answer '{correct}', defaulting to 'A'")
                    correct = "A"
                
                formatted.append({
                    "question_number": i + 1,
                    "question": q["question"],
                    "options": options_dict,
                    "correct_answer": correct,
                    "explanation": q.get("explanation", "")
                })
                
                logger.debug(f"Formatted question {i+1}: {q['question'][:50]}...")
                
            except Exception as e:
                logger.warning(f"Error formatting question {i}: {e}")
                continue
        
        return formatted
    
    def generate_quiz_text(
        self,
        topic: str,
        num_questions: int = 5,
        k: int = 10
    ) -> str:
        """
        Generate quiz and return as formatted text.
        
        Args:
            topic: Topic to quiz about
            num_questions: Number of questions
            k: Documents to retrieve
            
        Returns:
            Formatted quiz text
        """
        result = self.generate_quiz(topic, num_questions, k)
        
        if not result["success"] or not result["quiz"]:
            return result.get("message", "Kh√¥ng th·ªÉ t·∫°o quiz")
        
        lines = [f"üìù QUIZ: {topic.upper()}", "=" * 50, ""]
        
        for q in result["quiz"]:
            lines.append(f"C√¢u {q['id']}: {q['question']}")
            for letter, option in q["options"].items():
                lines.append(f"   {letter}. {option}")
            lines.append(f"   ‚úÖ ƒê√°p √°n: {q['correct_answer']}")
            if q.get("explanation"):
                lines.append(f"   üí° Gi·∫£i th√≠ch: {q['explanation']}")
            lines.append("")
        
        lines.append("=" * 50)
        lines.append(f"T·ªïng: {len(result['quiz'])} c√¢u h·ªèi")
        
        return "\n".join(lines)
