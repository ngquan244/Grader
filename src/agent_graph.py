"""
LangGraph ReAct Agent Implementation
AI Agent máº¡nh máº½ vá»›i kháº£ nÄƒng reasoning, planning vÃ  tool calling
"""
import json
from typing import TypedDict, Annotated, Sequence, Literal
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
from langchain_ollama import ChatOllama
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langgraph.graph.message import add_messages
from .tools import get_all_tools


# Define Agent State
class AgentState(TypedDict):
    """State cá»§a agent trong graph"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    next_action: str  # "continue", "end", "error"
    iteration_count: int  # Äáº¿m sá»‘ láº§n láº·p Ä‘á»ƒ trÃ¡nh infinite loop
    max_iterations: int  # Giá»›i háº¡n sá»‘ láº§n láº·p


class ReActAgent:
    """
    ReAct Agent implementation using LangGraph
    
    Features:
    - Multi-step reasoning
    - Tool calling with validation
    - Error handling & retry logic
    - Memory management
    - Self-reflection
    """
    
    def __init__(
        self,
        model_name: str = "llama3.1:latest",
        max_iterations: int = 10,
        temperature: float = 0.7
    ):
        self.model_name = model_name
        self.max_iterations = max_iterations
        self.temperature = temperature
        
        # Initialize LLM
        self.llm = ChatOllama(
            model=model_name,
            temperature=temperature,
        )
        
        # Get tools
        self.tools = get_all_tools()
        
        # Bind tools to LLM
        self.llm_with_tools = self.llm.bind_tools(self.tools)
        
        # Build graph
        self.graph = self._build_graph()
    
    def _create_system_prompt(self) -> str:
        """Táº¡o system prompt cho agent"""
        tool_descriptions = "\n".join([
            f"- {tool.name}: {tool.description}"
            for tool in self.tools
        ])
        
        return f"""Báº¡n lÃ  má»™t AI Agent thÃ´ng minh sá»­ dá»¥ng ReAct pattern (Reasoning + Acting).

**Available Tools:**
{tool_descriptions}

**Your Capabilities:**
1. PhÃ¢n tÃ­ch yÃªu cáº§u ngÆ°á»i dÃ¹ng má»™t cÃ¡ch sÃ¢u sáº¯c
2. Láº­p káº¿ hoáº¡ch nhiá»u bÆ°á»›c Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» phá»©c táº¡p
3. Sá»­ dá»¥ng tools khi cáº§n thiáº¿t
4. Tá»± Ä‘Ã¡nh giÃ¡ vÃ  Ä‘iá»u chá»‰nh hÃ nh Ä‘á»™ng
5. Xá»­ lÃ½ lá»—i vÃ  thá»­ láº¡i khi cáº§n

**Instructions:**
- Suy nghÄ© tá»«ng bÆ°á»›c má»™t (step-by-step reasoning)
- Giáº£i thÃ­ch lÃ½ do táº¡i sao báº¡n chá»n tool cá»¥ thá»ƒ
- Náº¿u tool tráº£ vá» lá»—i, hÃ£y phÃ¢n tÃ­ch vÃ  thá»­ cÃ¡ch khÃ¡c
- Khi hoÃ n thÃ nh, Ä‘Æ°a ra cÃ¢u tráº£ lá»i rÃµ rÃ ng vÃ  há»¯u Ã­ch
- LuÃ´n lá»‹ch sá»±, chÃ­nh xÃ¡c vÃ  sÃºc tÃ­ch

**QUAN TRá»ŒNG - Khi nÃ o sá»­ dá»¥ng tools:**
- CHá»ˆ sá»­ dá»¥ng execute_notebook tool KHI ngÆ°á»i dÃ¹ng YÃŠU Cáº¦U RÃ• RÃ€NG:
  + "Cháº¥m bÃ i", "cháº¥m Ä‘iá»ƒm", "kiá»ƒm tra bÃ i thi"
  + "Xem káº¿t quáº£", "tÃ­nh Ä‘iá»ƒm"
  + "Grade the exam", "check the answers"
- KHÃ”NG tá»± Ä‘á»™ng cháº¡y notebook khi:
  + NgÆ°á»i dÃ¹ng chá»‰ chÃ o há»i: "xin chÃ o", "hello", "hi"
  + Há»i thÃ´ng tin chung
  + Chat thÃ´ng thÆ°á»ng
- Vá»›i cÃ¢u há»i thÃ´ng thÆ°á»ng, tráº£ lá»i trá»±c tiáº¿p KHÃ”NG cáº§n tool

**Khi táº¡o quiz (quiz_generator tool):**
- CHá»ˆ sá»­ dá»¥ng KHI Ä‘Æ°á»£c yÃªu cáº§u: "táº¡o quiz", "gen quiz", "táº¡o Ä‘á» thi"
- Tool sáº½ tá»± Ä‘á»™ng Ä‘á»c PDF tá»« data/quiz/ vÃ  táº¡o file HTML
- Káº¿t quáº£ tráº£ vá» cÃ³ field "file_url" vá»›i Ä‘Æ°á»ng dáº«n file:///
- HÃƒY HIá»‚N THá»Š RÃ• RÃ€NG:
  + Link quiz (file_url) Ä‘á»ƒ sinh viÃªn cÃ³ thá»ƒ copy-paste vÃ o browser
  + HÆ°á»›ng dáº«n: "Copy link nÃ y vÃ  dÃ¡n vÃ o trÃ¬nh duyá»‡t Ä‘á»ƒ má»Ÿ quiz"
  + Sá»‘ cÃ¢u há»i Ä‘Ã£ táº¡o vÃ  file HTML path
- Äá»‹nh dáº¡ng output dá»… Ä‘á»c, Báº®T BUá»˜C hiá»ƒn thá»‹ URL Ä‘áº§y Ä‘á»§

**Khi cháº¥m Ä‘iá»ƒm bÃ i thi:**
- Sá»­ dá»¥ng tool execute_notebook Ä‘á»ƒ cháº¡y notebook
- Tool sáº½ tráº£ vá» JSON vá»›i thÃ´ng tin Ä‘áº§y Ä‘á»§
- HÃƒY TRÃCH XUáº¤T VÃ€ HIá»‚N THá»Š Äáº¦Y Äá»¦:
  + ThÃ´ng tin sinh viÃªn: student_id, name, email
  + Káº¿t quáº£: total_questions, correct, wrong, blank, score
  + Exam code vÃ  student code
- Äá»‹nh dáº¡ng cÃ¢u tráº£ lá»i dá»… Ä‘á»c, rÃµ rÃ ng

**Khi cÃ³ lá»—i xá»­ lÃ½ áº£nh:**
- Notebook sáº½ tráº£ vá» error vá»›i suggestion
- HÃƒY GIáº¢I THÃCH RÃ• RÃ€NG cho user:
  + Lá»—i gÃ¬ Ä‘Ã£ xáº£y ra (timing marks khÃ´ng Ä‘á»§, warp tháº¥t báº¡i, cells khÃ´ng Ä‘á»§...)
  + NguyÃªn nhÃ¢n cÃ³ thá»ƒ: áº£nh má», nghiÃªng, Ã¡nh sÃ¡ng kÃ©m
  + HÆ°á»›ng dáº«n: chá»¥p láº¡i áº£nh rÃµ nÃ©t, Ã¡nh sÃ¡ng Ä‘á»§, khÃ´ng bá»‹ lÃ³a
- KHÃ”NG chá»‰ copy error message, hÃ£y dá»‹ch sang tiáº¿ng Viá»‡t dá»… hiá»ƒu

**ReAct Pattern:**
1. Thought: Suy nghÄ© vá» váº¥n Ä‘á»
2. Action: Chá»n tool vÃ  thá»±c thi
3. Observation: Quan sÃ¡t káº¿t quáº£
4. Reflection: ÄÃ¡nh giÃ¡ vÃ  quyáº¿t Ä‘á»‹nh bÆ°á»›c tiáº¿p theo
"""
    
    def _should_continue(self, state: AgentState) -> Literal["tools", "end"]:
        """
        Quyáº¿t Ä‘á»‹nh xem agent nÃªn tiáº¿p tá»¥c hay káº¿t thÃºc
        """
        messages = state["messages"]
        last_message = messages[-1]
        
        # Kiá»ƒm tra giá»›i háº¡n iteration
        if state["iteration_count"] >= state["max_iterations"]:
            return "end"
        
        # Náº¿u message cuá»‘i cÃ³ tool calls, tiáº¿p tá»¥c
        if hasattr(last_message, "tool_calls") and len(last_message.tool_calls) > 0:
            return "tools"
        
        # Náº¿u khÃ´ng, káº¿t thÃºc
        return "end"
    
    def _call_model(self, state: AgentState) -> dict:
        """
        Gá»i LLM vá»›i context vÃ  tools
        """
        messages = state["messages"]
        
        # ThÃªm system message náº¿u chÆ°a cÃ³
        if not messages or not isinstance(messages[0], SystemMessage):
            system_msg = SystemMessage(content=self._create_system_prompt())
            messages = [system_msg] + list(messages)
        
        # Call LLM
        response = self.llm_with_tools.invoke(messages)
        
        # TÄƒng iteration count
        return {
            "messages": [response],
            "iteration_count": state["iteration_count"] + 1
        }
    
    def _build_graph(self) -> StateGraph:
        """
        XÃ¢y dá»±ng StateGraph cho agent
        
        Flow:
        START -> agent -> [tools | END]
        tools -> agent (loop back for reflection)
        """
        # Create graph
        workflow = StateGraph(AgentState)
        
        # Add nodes
        workflow.add_node("agent", self._call_model)
        workflow.add_node("tools", ToolNode(self.tools))
        
        # Set entry point
        workflow.set_entry_point("agent")
        
        # Add conditional edges
        workflow.add_conditional_edges(
            "agent",
            self._should_continue,
            {
                "tools": "tools",
                "end": END
            }
        )
        
        # Add edge from tools back to agent for reflection
        workflow.add_edge("tools", "agent")
        
        # Compile
        return workflow.compile()
    
    def invoke(self, user_input: str, history: list[dict] = None) -> dict:
        """
        Thá»±c thi agent vá»›i user input
        
        Args:
            user_input: CÃ¢u há»i/yÃªu cáº§u cá»§a user
            history: Lá»‹ch sá»­ chat (optional)
        
        Returns:
            dict vá»›i response vÃ  metadata
        """
        # Prepare messages
        messages = []
        
        # Add history if provided
        if history:
            for msg in history:
                if msg["role"] == "user":
                    messages.append(HumanMessage(content=msg["content"]))
                elif msg["role"] == "assistant":
                    messages.append(AIMessage(content=msg["content"]))
        
        # Add current user input
        messages.append(HumanMessage(content=user_input))
        
        # Create initial state
        initial_state = {
            "messages": messages,
            "next_action": "continue",
            "iteration_count": 0,
            "max_iterations": self.max_iterations
        }
        
        # Run graph
        try:
            result = self.graph.invoke(initial_state)
            
            # Extract response
            last_message = result["messages"][-1]
            
            if isinstance(last_message, AIMessage):
                response_content = last_message.content
            else:
                response_content = str(last_message)
            
            # Extract tool calls info for debugging
            tool_calls_info = []
            for msg in result["messages"]:
                if isinstance(msg, AIMessage) and hasattr(msg, "tool_calls"):
                    if msg.tool_calls:
                        tool_calls_info.extend([
                            {
                                "tool": tc["name"],
                                "args": tc.get("args", {})
                            }
                            for tc in msg.tool_calls
                        ])
            
            return {
                "response": response_content,
                "iterations": result["iteration_count"],
                "tools_used": tool_calls_info,
                "success": True
            }
        
        except Exception as e:
            return {
                "response": f"âŒ Lá»—i: {str(e)}",
                "error": str(e),
                "success": False
            }
    
    def stream(self, user_input: str, history: list[dict] = None):
        """
        Stream agent execution (for real-time UI updates)
        """
        # Prepare messages
        messages = []
        
        if history:
            for msg in history:
                if msg["role"] == "user":
                    messages.append(HumanMessage(content=msg["content"]))
                elif msg["role"] == "assistant":
                    messages.append(AIMessage(content=msg["content"]))
        
        messages.append(HumanMessage(content=user_input))
        
        # Create initial state
        initial_state = {
            "messages": messages,
            "next_action": "continue",
            "iteration_count": 0,
            "max_iterations": self.max_iterations
        }
        
        # Stream execution
        for output in self.graph.stream(initial_state):
            yield output


# Factory function
def create_agent(model: str = "llama3.1:latest", max_iterations: int = 10) -> ReActAgent:
    """Factory function Ä‘á»ƒ táº¡o agent"""
    return ReActAgent(model_name=model, max_iterations=max_iterations)


# Test function
if __name__ == "__main__":
    # Test agent
    agent = create_agent()
    
    test_queries = [
        "Xin chÃ o!",
        "Cho tÃ´i Ä‘iá»ƒm Kaggle",
        "TÃ­nh 25 * 4 + 10",
        "Giáº£i thÃ­ch machine learning lÃ  gÃ¬?"
    ]
    
    print("ðŸš€ Testing ReAct Agent\n")
    
    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"User: {query}")
        print(f"{'='*60}")
        
        result = agent.invoke(query)
        
        print(f"\n Agent: {result['response']}")
        print(f"\n Metadata:")
        print(f"  - Iterations: {result.get('iterations', 0)}")
        print(f"  - Tools used: {result.get('tools_used', [])}")
        print(f"  - Success: {result.get('success', False)}")
